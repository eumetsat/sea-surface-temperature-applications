{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/tools/frameworks/-/raw/main/img/Standard_banner.png' align='right' width='100%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"../../../Index.ipynb\"><< Index</a>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#138D75\">**Copernicus Marine Training Service**</font> <br>\n",
    "**Copyright:** 2024 EUMETSAT <br>\n",
    "**License:** MIT <br>\n",
    "**Authors:** Ben Loveday (EUMETSAT/Innoflair UG), Hayley Evers-King (EUMETSAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "  <div style=\"width:100%\">\n",
    "    <div style=\"float:left\"><a href=\"https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/applications/ocean-case-studies\"><img src=\"https://img.shields.io/badge/open-EUMETLAB-E67E22.svg?style=flat&logo=data:image/png;base64,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\" alt=\"Open in EUMETLAB\"></a></div>\n",
    "    <div style=\"float:left\"><p>&emsp;</p></div>\n",
    "  </div>\n",
    "  \n",
    "  <div style=\"width:100%\">\n",
    "    <div style=\"float:left\"><a href=\"https://mybinder.org/v2/git/https%3A%2F%2Fgitlab.eumetsat.int%2Feumetlab%2Foceans%2Focean-training%2Fapplications%2ocean-case-studies/HEAD?urlpath=%2Ftree%2FCase_studies%2FCSM_ocean%2FAtl_Med_anomalies%2FAtlantic_Med_SST_anomalies.ipynb\"><img src=\"https://mybinder.org/badge_logo.svg\" alt=\"Open in Binder\"></a></div>\n",
    "    <div style=\"float:left\"><p>&emsp;</p></div>\n",
    "  </div>\n",
    "\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<h3>Ocean case studies</h3></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>PREREQUISITES </b>\n",
    "\n",
    "This notebook has the following prerequisites:\n",
    "- **<a href=\"https://eoportal.eumetsat.int/\" target=\"_blank\">A EUMETSAT Earth Observation Portal account</a>** to download from the EUMETSAT Data Store\n",
    "- **<a href=\"https://data.marine.copernicus.eu/register\" target=\"_blank\">A Copernicus Marine Service (CMEMS) account</a>** to download data from the CMEMS Data Store\n",
    "\n",
    "There are no prerequisite notebooks for this module, but you may wish to look at the following notebooks on using SLSTR data; <br>\n",
    "- **<a href=\"https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/sensors/learn-SLSTR\" target=\"_blank\">Learn SLSTR (EUMETSAT Gitlab)</a>**\n",
    "\n",
    "</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sea surface temperature anomalies and trends in the Northern Atlantic and Mediterranean Sea\n",
    "\n",
    "### Data used\n",
    "\n",
    "| Dataset | EUMETSAT Data Store<br>collection ID| EUMETSAT collection<br>description | WEkEO dataset ID | WEkEO description |\n",
    "|:--------------------:|:-----------------------:|:-------------:|:-----------------:|:-----------------:|\n",
    "| Sentinel-3 SLSTR level-2P | EO:EUM:DAT:0412 | <a href=\"https://user.eumetsat.int/catalogue/EO:EUM:DAT:0179\" target=\"_blank\">Description</a> | EO:EUM:DAT:SENTINEL-3:SL_2_WST___ | <a href=\"https://www.wekeo.eu/data?view=dataset&dataset=EO%3AEUM%3ADAT%3ASENTINEL-3%3ASL_2_WST___&initial=1\" target=\"_blank\">Description</a> |\n",
    "| Global OSTIA SST (Reprocessed) | - | - | EO:MO:DAT:SST_GLO_SST_L4_REP_OBSERVATIONS_010_011 | <a href=\"https://www.wekeo.eu/data?view=dataset&dataset=EO%3AMO%3ADAT%3ASST_GLO_SST_L4_REP_OBSERVATIONS_010_011\" target=\"_blank\">Description</a> |\n",
    "| Global OSTIA SST (Near real-time) | - | - | EO:MO:DAT:SST_GLO_SST_L4_NRT_OBSERVATIONS_010_001 | <a href=\"https://www.wekeo.eu/data?view=dataset&dataset=EO%3AMO%3ADAT%3ASST_GLO_SST_L4_NRT_OBSERVATIONS_010_001\" target=\"_blank\">Description</a> |\n",
    "\n",
    "### Learning outcomes\n",
    "\n",
    "At the end of this notebook you will know how to;\n",
    "* how to acquire level-4 SST products from the Copernicus Marine Service (CMEMS)\n",
    "* how to acquire Copernicus Sentinel-3 SLSTR level-2P SST products from the EUMETSAT Data Store\n",
    "* how to generate SST climatologies, anomalies and time series\n",
    "* how to compare SST products and the caveats to doing so\n",
    "\n",
    "### Outline\n",
    "\n",
    "In the last few years, we have observed extreme warm temperatures across the global oceans. With several regions recording temperatures of exceptional magnitude, questions are asked about how these measurements fit with historical trends, and what the impacts of extreme temperatures will be on the weather we experience, and marine life. Sea surface temperature measurements from satellites, provide data at suitable temporal and spatial scales to contribute to answering these questions, however product selection is key.\n",
    "\n",
    "In this python-based Jupyter Notebook we discuss some of the key factors that should inform the choice or data selection when monitoring anomalies, including;\n",
    "* the fundamental differences between SST variables (e.g. *SSTskin* vs *SSTfnd*), when can they be compared, and with what caveats?\n",
    "* the differences between climate data record, reprocessed and operational (or near real-time) data and\n",
    "* what our choices of data say about the conclusions we can draw.\n",
    "\n",
    "In practice, SST is a broad term that covers a range of measurements. These are well described on figure 1, which gives the Group for High resolution Sea Surface Temperature (<a href=\"https://www.ghrsst.org/\" target=\"_blank\">GHRSST</a>) definitions for a number of key quantities. Infra-red (IR) based satellites (e.g. Sentinel-3 SLSTR) retrieve skin temperature (*SSTskin*), while microwave instruments retrieve sub-skin temperature (*SSTsubskin*). In general, these are the single-sensor variables that are distributed at level-2P.\n",
    "\n",
    "*Note: satellites measure radiance and brightness temperature and we “retrieve” SST from it. We do not measure SST directly.*\n",
    "\n",
    "<figure>\n",
    "  <img src='https://www.ghrsst.org/wp-content/uploads/2021/04/newerSSTdef.gif' width='50%'/>\n",
    "  <figcaption>Figure 1: GHRSST SST definitions (Credit: GHRSST)</figcaption>\n",
    "</figure>\n",
    "\n",
    "From figure 1, it is clear that *SSTskin* and *SSTsubskin* can vary greatly from day to night and from light winds to strong winds. Diurnal warming heats the surface layers substantially during the day, unless the surface layers are mixed by strong winds. The skin effect, which cools the immediate surface due to the equilibrium with the cooler atmosphere, keeps *SSTskin* slightly cooler than *SSTsubskin*. *SSTfnd*, the foundation temperature, represents the level at which the temperature is free from diurnal variability. It is common to find *SSTfnd* distributed as a level-3 or level-4 product as these typically combine data from multiple sensors, which measure at different times of day, and in some cases, incorporate data from both IR and MW retrievals. With this in mind, we already have some idea of when we can compare *SSTskin* and *SSTfnd*, which we will discuss more later in this notebook.\n",
    "\n",
    "SST records also vary substantially in length, timeliness and quality. Climate data records represent the highest quality data; consistently processed, bias corrected and fully, independently validated. However, they are produced episodically and are not operational, e.g. are not produced daily. They enable us to construct stable and valid climatologies, but not monitor current events. Reprocessed data is consistently processed, and tends to be updated more regularly, but is not quite CDR quality. Operational data, including that available at near real-time, is available quickly but has the lowest quality and, in some cases, may have different processing to it’s analogous reprocessing (where it exists). This presents us with a challenge when we wish to monitor an event, but need to compare to a historical baseline. What part of the anomaly is due to the dynamics of a system, and what part is due to the difference in the processing? In practice, this is hard to ascertain, and we need to take some care.\n",
    "\n",
    "Lets work with some data and see these impacts in action. We will do this is sections, as shown in the table on contents.\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='TOCTOP'></a>Contents\n",
    "\n",
    "</div>\n",
    "\n",
    " 1. [Step 1: Setting up our analysis](#section1)\n",
    " 1. [Step 2: Defining functions](#section2)\n",
    " 1. [Step 3: Acquiring an SST climatology](#section3)\n",
    " 1. [Step 4: Preparing the SST climatology](#section4)\n",
    " 1. [Step 5: Calculating a level-4 SST anomaly](#section5)\n",
    " 1. [Step 6: Downloading level-2P SLSTR SST granules](#section6)\n",
    " 1. [Step 7: Calculating a level-2P SST anomaly](#section7)\n",
    " 1. [Step 8: Downloading and plotting time series](#section8)\n",
    " 1. [Step 9: Conclusions](#section9)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section1'></a>1. Setting up our analysis\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by importing all of the libraries that we need to run this notebook. If you have built your python using the environment file provided in this repository, then you should have everything you need. For more information on building environment, please see the repository **<a href=\"../../../../README.md\" target=\"_blank\">README</a>**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cartopy                                        # a library that supports mapping and projection\n",
    "import datetime                                       # a library that allows us to work with dates and times\n",
    "import glob                                           # a package that helps with file searching\n",
    "import matplotlib.pyplot as plt                       # a library the provides plotting capability\n",
    "from matplotlib import gridspec                       # a library the provides plotting capability\n",
    "import numpy as np                                    # a library that lets us work with arrays; we import this with a new name \"np\"\n",
    "import os                                             # a library that allows us access to basic operating system commands\n",
    "import xarray as xr                                   # a powerful library that helps us work efficiently with multi-dimensional arrays\n",
    "import eumdac                                         # a tool that helps us download via the eumetsat/data-store\n",
    "import shutil                                         # a library that allows us access to basic operating system commands\n",
    "import copernicusmarine                               # a library to help us access CMEMS data\n",
    "from scipy.interpolate import griddata                # a library that provides interpolation options\n",
    "from scipy import stats                               # a library that support statistical analysis\n",
    "import bokeh.plotting as bk                           # a library that supports plotting\n",
    "from bokeh.palettes import RdBu11, interp_palette     # as above\n",
    "from bokeh.models import ColorBar, LinearColorMapper  # as above\n",
    "import pandas as pd                                   # a library for time series analysis\n",
    "from pathlib import Path                              # a library that helps construct system path objects\n",
    "import getpass                                        # a library to help us enter passwords\n",
    "import warnings                                       # a library the helps us to manage warnings\n",
    "\n",
    "# turn off warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# initiate \"bokeh\" plot\n",
    "bk.output_notebook()\n",
    "\n",
    "# set plot font size\n",
    "plt.rc('font', size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to set a few parameters to run our notebook. Below we will define an output directory (\"./products\") to store our downloaded data. Then we will set two keys to determing if we want to download OSTIA data from the CMEMS Data Store and SLSLT data from the EUMETSAT Data Store. Downloading data is the slowest part of this notebook. It will take ~15 minutes to download all the data, but only ~2 mins to run without download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a download directory for our OLCI products\n",
    "download_dir = os.path.join(os.getcwd(), \"products\")\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# Data downloading options\n",
    "download_SLSTR_granules = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets set up a couple of quick plotting variables..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set some mapping vars\n",
    "color_mapper = LinearColorMapper(interp_palette(RdBu11, 256), low=-4, high=4)\n",
    "coast = cartopy.feature.NaturalEarthFeature(category='physical', scale='10m', facecolor='none', name='coastline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we coome to the important bit; data selection.\n",
    "\n",
    "In the cell below we will identify two level-4 foundation temperature (*SSTfnd*) records to work with; the OSTIA multi-year reprocessing collection, and the analogous OSTIA operational collection. The `dataset_???` codes relate to the products as they are stored in the CMEMS Data Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Multi-year reprocessing\n",
    "dataset_my = 'METOFFICE-GLO-SST-L4-REP-OBS-SST'\n",
    "\n",
    "# Near real-time\n",
    "dataset_nrt = 'METOFFICE-GLO-SST-L4-NRT-OBS-SST-V2'\n",
    "\n",
    "CMEMS_dataset_variables = [\"analysed_sst\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we will define a region of interest for our level-4 products and the time bounds for both the climatology (applied to the reprocessing) and the operational product. We are defining a climatology for a single day, but we will also set an ROI for a time series extraction over the entire period (climatology + operational) for later comparison on a day-by-day basis. We will use this time series data in the companion **<a href=\"./Med_MHW_2023.ipynb\" target=\"_blank\">Marine heatwaves in the Mediterranean Sea in 2023</a>** notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L4 ROI\n",
    "L4_region = [-90.0, 30.0, 45.0, 75.0] # W, S, E, N\n",
    "\n",
    "# L4 Time series ROI\n",
    "TS_region = [10, 36, 15, 42] # W, S, E, N\n",
    "\n",
    "# climatology\n",
    "start_year = 1982\n",
    "end_year = 2024\n",
    "month = datetime.datetime.today().month\n",
    "day = datetime.datetime.today().day - 2\n",
    "\n",
    "# operational\n",
    "nrt_year = datetime.datetime.today().year\n",
    "formatted_month = datetime.datetime(nrt_year, month, day).strftime('%B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lets set the collection ID for our SST data set from the EUMETSAT Data Store. In this case, this code applies to the operational SLSTR SST (*SSTskin*) collection...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select collectionID\n",
    "collectionID = 'EO:EUM:DAT:0412'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and set our ROI for our L2 region. The operational year defined above will be used to set the time bounds. To facilitate quicker plotting, we will also define a subsample variable which can be increased to speed up plotting, or dropped to 1 for full resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 ROI\n",
    "L2_region = [-10, 30, 30, 45] # W, S, E, N\n",
    "subsample = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we are ready to go! There are no more quantities to define below. If you wish to adapt this notebook for your own purposes you should be able to do most of it by manipulating the parameters above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "\n",
    "## <a id='section2'></a>2. Defining functions\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things simpler we are defining a few functions that contain some code we want to run multiple times in this notebook. These cells are hidden by default, as we won't discuss them much, but you can expand the cells to read the function descriptions if you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_plot():\n",
    "    '''\n",
    "    This function does a quick plot initialisation\n",
    "    '''\n",
    "    gs = gridspec.GridSpec(3, 1, height_ratios=[10, 1, 1])\n",
    "    gs.update(wspace=0.01, hspace=0.01)\n",
    "\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embellish_plot(m):\n",
    "    \"\"\"Quick function to embellish plots with gridlines and labels\n",
    "\n",
    "    Args:\n",
    "        m (axis): the axis to plot into\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Embellish with gridlines\n",
    "    m.add_feature(cartopy.feature.NaturalEarthFeature('physical', 'land', '10m', edgecolor='k', facecolor='#546d51', linewidth=0.5), zorder=500)\n",
    "    g1 = m.gridlines(draw_labels = True, linestyle='--', linewidth=0.5, zorder=1000)\n",
    "    g1.top_labels = g1.right_labels = False\n",
    "    g1.xlabel_style = g1.ylabel_style = {'color': '0.5'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section3'></a>3. Acquiring an SST climatology\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build our climatology, we will access data from the Copernicus Marine Service using the Copernicus Marine API. This loads data directly into memory, without the need to download anything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "### Accessing Copernicus Marine Service products\n",
    "\n",
    "To retrieve the data, we need will use the <a href=\"https://help.marine.copernicus.eu/en/articles/7949409-copernicus-marine-toolbox-introduction\" target=\"_blank\">Copernicus Marine API</a>. This allows us to remotely subset the data and read it directly into memory, for immediate use. If you are working with the recommended Anaconda Python distribution and used the environment file included in this repository (environment.yml) to build this python environment (as detailed in the README), you will already have installed this. If not, you can install the toolkit using;\n",
    "\n",
    "`conda install -c conda-forge copernicusmarine`\n",
    "\n",
    "To download data using the Copernicus Marine API, you need to provide credentials. To obtain these, you should register at the <a href=\"https://data.marine.copernicus.eu/register\" target=\"_blank\">Copernicus Marine Service</a> for an account and take note of you `username` and `password`. If you do not already have a local credentials file, you will be prompted to enter your credentials when you run the cell below. This will create the required local credentials file, so that you only need to run this once.\n",
    "\n",
    "*Note: For more information on authentication options please see this <a href=\"https://help.marine.copernicus.eu/en/articles/8185007-copernicus-marine-toolbox-credentials-configuration\" target=\"_blank\">web article</a>.*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default location expected by the copernicusmarine package\n",
    "copernicus_marine_credentials_file = Path(Path.home() / '.copernicusmarine' / '.copernicusmarine-credentials')\n",
    "\n",
    "# Create it only if it does not already exists\n",
    "if not copernicus_marine_credentials_file.is_file():\n",
    "    copernicusmarine.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST_clim_data = []\n",
    "for clim_year in range(start_year, 1986):\n",
    "    SST_clim_data.append(copernicusmarine.open_dataset(\n",
    "               dataset_id = dataset_my,\n",
    "               variables=['analysed_sst'],\n",
    "               minimum_longitude=L4_region[0],\n",
    "               maximum_longitude=L4_region[2],\n",
    "               minimum_latitude=L4_region[1],\n",
    "               maximum_latitude=L4_region[3],\n",
    "               start_datetime=\"{clim_year}-{month}-{day}T00:00:00.000Z\".format(clim_year = clim_year, month = str(month).zfill(2), day = str(day).zfill(2)),\n",
    "               end_datetime=\"{clim_year}-{month}-{day}T00:00:00.000Z\".format(clim_year = clim_year, month = str(month).zfill(2), day = str(day).zfill(2)),\n",
    "               ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST_clim_data = xr.concat(SST_clim_data, dim='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section4'></a>4. Preparing the SST climatology\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the files for our climatology (by default, these should be called CLIM_OSTIA_SST_????, and stored in the \"products\" folder) we need to gather them and create the daily climatology itself. The `xarray` library allows us to open all the downloaded files at once and then take a simple average in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST_clim = SST_clim_data[\"analysed_sst\"].mean(dim='time')\n",
    "LON, LAT = np.meshgrid(SST_clim_data[\"longitude\"], SST_clim_data[\"latitude\"]) # for later use...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our daily climatology, we can go ahead and plot it on our chosen projection (Plate-Carree by default).\n",
    "*Note: we are calling a couple of our functions to set up (`set_plot`) our plot and embellish it (`embellish_plot`) with gridlines, coasts, land etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup figure\n",
    "fig = plt.figure(figsize=(16, 6), dpi=300)\n",
    "\n",
    "gs = set_plot()\n",
    "\n",
    "# plot\n",
    "axes_m = plt.subplot(gs[0,0], projection=cartopy.crs.PlateCarree())\n",
    "axes_m.set_extent([L4_region[0], L4_region[2], L4_region[1], L4_region[3]], crs=cartopy.crs.PlateCarree())\n",
    "p1 = axes_m.pcolormesh(SST_clim_data[\"longitude\"], SST_clim_data[\"latitude\"],\n",
    "                       SST_clim - 273.15, cmap=\"RdYlBu_r\", transform=cartopy.crs.PlateCarree())\n",
    "# embellish plot\n",
    "embellish_plot(axes_m)\n",
    "axes_m.plot([L2_region[ii] for ii in [0,0,2,2,0]], [L2_region[ii] for ii in [1,3,3,1,1]], c=\"k\", linestyle='--', linewidth=1.0, zorder=10000)\n",
    "axes_m.annotate(\"L2 region\", (L2_region[0], L2_region[-1]+1), xycoords='data', zorder=10000)\n",
    "axes_m.plot([TS_region[ii] for ii in [0,0,2,2,0]], [TS_region[ii] for ii in [1,3,3,1,1]], c=\"0.5\", linestyle='--', linewidth=1.0, zorder=10000)\n",
    "axes_m.annotate(\"TS region\", (TS_region[0], TS_region[1]-2), xycoords='data', c=\"0.5\", zorder=10000)\n",
    "\n",
    "# colorbar\n",
    "axes_c = plt.subplot(gs[2,0])\n",
    "cbar = plt.colorbar(p1, cax=axes_c, orientation='horizontal')\n",
    "clabel = f\"OSTIA level-4 foundation temperature climatology ({start_year}:{end_year}) for {day} {formatted_month}\"\n",
    "cbar.set_label(clabel + ' [$^{o}C$]')\n",
    "plt.savefig(\"OSTIA_climatology.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected from a long (40 year by default) climatology, most of the SST variabilty has been smoothed out, but we can still some evidence of the Gulf Stream front and some broadly expected patterns of cooling towards the polar regions. We have also indicated the areas we will focus on to look at our SST anomalies and time series (TS)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section5'></a>5. Calculating a level-4 SST anomaly\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will calculate the anomaly between our reprocessed SST foundation temperature climatology and our recent operational product. The cells below will download the data we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST_nrt_data = copernicusmarine.open_dataset(\n",
    "           dataset_id = dataset_nrt,\n",
    "           variables=['analysed_sst'],\n",
    "           minimum_longitude=L4_region[0],\n",
    "           maximum_longitude=L4_region[2],\n",
    "           minimum_latitude=L4_region[1],\n",
    "           maximum_latitude=L4_region[3],\n",
    "           start_datetime=\"{nrt_year}-{month}-{day}T00:00:00.000Z\".format(nrt_year = nrt_year, month = str(month).zfill(2), day = str(day).zfill(2)),\n",
    "           end_datetime=\"{nrt_year}-{month}-{day}T00:00:00.000Z\".format(nrt_year = nrt_year, month = str(month).zfill(2), day = str(day).zfill(2)),\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST_anomaly = np.squeeze(np.array(SST_nrt_data[\"analysed_sst\"] - SST_clim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see how our anomaly looks. We will makes this plot with the Bokeh library, as it allows us to interact with the resulting map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lonmin, lonmax = np.nanmin(SST_clim_data[\"longitude\"]), np.nanmax(SST_clim_data[\"longitude\"])\n",
    "latmin, latmax = np.nanmin(SST_clim_data[\"latitude\"]), np.nanmax(SST_clim_data[\"latitude\"])\n",
    "\n",
    "f1 = bk.figure(width=1280, height=720, x_range=[lonmin, lonmax], y_range=[latmin, latmax])\n",
    "f1.image(image=[SST_anomaly], x=[lonmin], y=[latmin], dw=[lonmax-lonmin], dh=[latmax-latmin], color_mapper=color_mapper)\n",
    "\n",
    "for val in coast.geometries():\n",
    "    coast_lons, coast_lats = val.xy\n",
    "    f1.line(coast_lons, coast_lats, color='black', line_width=0.5)\n",
    "    \n",
    "color_bar = ColorBar(color_mapper=color_mapper, label_standoff=12, border_line_color=None, location=(0,0))\n",
    "f1.add_layout(color_bar, 'right')\n",
    "\n",
    "bk.show(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The anomaly plot clearly shows that, for our chosen data (18th July 2023), much of the Atlantic shows substantial warming. We can also see large anomalies, both positive and negative, around the Gulf Stream, but this is quite common to see in any dynamical system that may have substantial interannual and intra-annual variability. More concerning is the particulary severe warming in the Western Atlantic and Western Mediterranean Sea.\n",
    "\n",
    "Although we can draw information from this plot, we need to bear a few caveats in mind;\n",
    "1. The OSTIA climatology we are using is reprocessed data, which is high quality, but not a climate data record. As such, it is hard to draw any climate related conclusions from this.\n",
    "2. The near-real time operational OSTIA product we are using is **not** the same quality as the reprocessed data, and may not even have the same processing as the reprocessing product. This makes point 1 all the more serious. We can look at events from this, but not infer long term variability without extensive further analysis.\n",
    "\n",
    "However, it does look really, really bad...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section6'></a>6. Downloading level-2P SLSTR SST granules\n",
    "[Back to top](#TOC6TOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our near real-time OSTIA data is at 0.05 degree resolution in is available with about 18 hours of latency. If we want to take a look at finer scale and/or more recent data, we can choose to calculate our anomaly using 1 km near real-time level-2P SLSTR data. However, we must take *extreme care* with this. Firstly, based on figure 1, we know as we are comparing *SSTskin* with *SSTfnd*, we **must** only use nighttime SLSTR data. Secondly, when we do the comparison we will still have the skin effect contained in the SLSTR observations. We can actually correct for this, but it is beyond the scope of this notebook to do so.\n",
    "\n",
    "We will download the SLSTR level-2 products from the EUMETAT Data Store."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "### Accessing the EUMETSAT Data Store\n",
    "\n",
    "To access Copernicus marine data from the <a href=\"https://data.eumetsat.int \" target=\"_blank\">EUMETSAT Data Store</a>, we will use the EUMETSAT Data Access Client (`eumdac`) python package. If you are working with the recommended Anaconda Python distribution and used the environment file included in this repository (environment.yml) to build this python environment (as detailed in the README), you will already have installed this. If not, you can install eumdac using;\n",
    "\n",
    "`conda install -c eumetsat eumdac`\n",
    "\n",
    "You can also find the source code on the <a href=\"https://gitlab.eumetsat.int/eumetlab/data-services/eumdac \" target=\"_blank\">EUMETSAT GitLab</a>. Please visit the EUMETSAT user portal for more information on the <a href=\"https://user.eumetsat.int/data-access/data-store \" target=\"_blank\">EUMETSAT Data Store</a> and <a href=\"https://user.eumetsat.int/resources/user-guides/eumetsat-data-access-client-eumdac-guide \" target=\"_blank\">eumdac</a>.\n",
    "\n",
    "To download data from the EUMETSDAT Data Store via API, you need to provide credentials. To obtain these you should first register at for an <a href=\"https://eoportal.eumetsat.int/\" target=\"_blank\">EUMETSAT Earth Observation Portal account</a>. Once you have an account, you can retrieve your `<your_consumer_key>` and `<your_consumer_secret>` from the <a href=\"https://api.eumetsat.int/api-key/ \" target=\"_blank\">\"EUMETSAT Data Store API\"</a> page (*Note: you must click the \"Show hidden fields\" button at the bottom of the page to see the relevant fields*). If you do not already have a local credentials file, you will be prompted to enter your credentials when you run the cell below. This will create the required local credentials file, so that you only need to run this once.\n",
    "\n",
    "*Note: your key and secret are permanent, so you should take care to never share them*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load credentials\n",
    "eumdac_credentials_file = Path(Path.home() / '.eumdac' / 'credentials')\n",
    "\n",
    "if os.path.exists(eumdac_credentials_file):\n",
    "    consumer_key, consumer_secret = Path(eumdac_credentials_file).read_text().split(',')\n",
    "else:\n",
    "    # creating authentication file\n",
    "    consumer_key = input('Enter your consumer key: ')\n",
    "    consumer_secret = getpass.getpass('Enter your consumer secret: ')\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(eumdac_credentials_file), exist_ok=True)\n",
    "        with open(eumdac_credentials_file, \"w\") as f:\n",
    "            f.write(f'{consumer_key},{consumer_secret}')\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "token = eumdac.AccessToken((consumer_key, consumer_secret))\n",
    "print(f\"This token '{token}' expires {token.expiration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `download_SLSTR_granules` is True, The cell below will fetch all the **night-time** (`orbitdir='ASCENDING'`) near real-time (`timeliness='NR'`) SLSTR granules over our region and time of interest and store them in our downloads directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create data store object\n",
    "datastore = eumdac.DataStore(token)\n",
    "\n",
    "# space/time filter the collection for products\n",
    "selected_collection = datastore.get_collection(collectionID)\n",
    "\n",
    "# expand sub-region into a polygon\n",
    "L2_region_poly = [[L2_region[0], L2_region[1]], [L2_region[0], L2_region[3]], [L2_region[2], L2_region[3]], [L2_region[2], L2_region[1]], [L2_region[0], L2_region[1]]]\n",
    "\n",
    "count = 0\n",
    "if download_SLSTR_granules:\n",
    "    products = selected_collection.search(\n",
    "        geo='POLYGON(({}))'.format(','.join([\"{} {}\".format(*coord) for coord in L2_region_poly])),\n",
    "        dtstart=datetime.datetime(nrt_year, month, day-1, datetime.datetime.now().hour, 0, 0), \n",
    "        dtend=datetime.datetime(nrt_year, month, day, datetime.datetime.now().hour, 0, 0),\n",
    "        timeliness = 'NR', \n",
    "        orbitdir= 'ASCENDING')\n",
    "\n",
    "    print(f\"Found {len(products)} matching products\")\n",
    "    \n",
    "    for product in products:\n",
    "        count = count + 1\n",
    "        for entry in product.entries:\n",
    "            if \".nc\" in entry:\n",
    "                fname = os.path.join(os.getcwd(), 'products', os.path.basename(entry))\n",
    "                if not os.path.exists(fname):\n",
    "                    with product.open(entry=entry) as fsrc, open(fname, mode='wb') as fdst:\n",
    "                        print(f'Downloading ({count}) {fsrc.name}.')\n",
    "                        shutil.copyfileobj(fsrc, fdst)\n",
    "                    print(f'Download of file {fsrc.name} finished.')\n",
    "                else:\n",
    "                    print(f'{fsrc.name} exists, skipping.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section7'></a>7. Calculating a level-2P SST anomaly\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets calculate our anomaly between the SLSTR level-2P granules and the OSTIA level-4 climatology. First we need to collect the files..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read SLSTR granules:\n",
    "files = glob.glob(os.path.join(download_dir,\"*L2P_*.nc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will plot them. The cell below opens each SLSTR granule in turn and does the following:\n",
    "* reads in the `sea_surface_temperature` field\n",
    "* corrects the SST with the `sses_bias` field\n",
    "* applies the `quality_level` flags to the SST field, keeping only data where the quality level = 5 (the highest)\n",
    "* interpolates the climatology onto the SLSTR SST field grid\n",
    "* calculates the anomaly\n",
    "* and finally plots the granule\n",
    "\n",
    "Note: for maximum spatial resolution, but slower plotting set `subsample` to 1. For converse, set subsample higher...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup figure\n",
    "fig = plt.figure(figsize=(16, 9), dpi=300)\n",
    "plt.rc('font', size=12)\n",
    "\n",
    "gs = set_plot()\n",
    "\n",
    "axes_m = plt.subplot(gs[0,0], projection=cartopy.crs.PlateCarree())\n",
    "axes_m.set_extent([L2_region[0], L2_region[2], L2_region[1], L2_region[3]], crs=cartopy.crs.PlateCarree())\n",
    "\n",
    "# blank out the background\n",
    "p1 = axes_m.pcolormesh(SST_clim_data[\"longitude\"], SST_clim_data[\"latitude\"], SST_anomaly*0, cmap=\"RdBu_r\",\n",
    "                       transform=cartopy.crs.PlateCarree(), vmin=-5, vmax=5)\n",
    "count = 0\n",
    "for file in files:\n",
    "    count = count + 1\n",
    "    print(f\"Processing granule {count} of {len(files)}\")\n",
    "    SST_granule = xr.open_mfdataset(file)\n",
    "\n",
    "    L2_LON = np.array(SST_granule[\"lon\"][::subsample,::subsample])\n",
    "    L2_LAT = np.array(SST_granule[\"lat\"][::subsample,::subsample])\n",
    "    L2_SST = np.squeeze(np.array(SST_granule[\"sea_surface_temperature\"][0, ::subsample,::subsample] + SST_granule[\"sses_bias\"][0, ::subsample,::subsample]))\n",
    "    L2_QC = np.squeeze(np.array(SST_granule[\"quality_level\"][0, ::subsample,::subsample]))\n",
    "    L2_SST[L2_QC < 5] = np.nan\n",
    "\n",
    "    # interp clim to granule\n",
    "    SST_clim_interp = griddata((LON.ravel(), LAT.ravel()), np.array(SST_clim).ravel(),\n",
    "                               (L2_LON.ravel(), L2_LAT.ravel()),\n",
    "                               method=\"nearest\").reshape(np.shape(L2_LON))\n",
    "   \n",
    "    p1 = plt.pcolormesh(L2_LON, L2_LAT, L2_SST - SST_clim_interp, cmap=\"RdBu_r\", vmin = -4, vmax = 4)\n",
    "    SST_granule.close()\n",
    "\n",
    "embellish_plot(axes_m)\n",
    "\n",
    "axes_m.plot([TS_region[ii] for ii in [0,0,2,2,0]], [TS_region[ii] for ii in [1,3,3,1,1]], c=\"0.5\", linestyle='--', linewidth=1.0)\n",
    "axes_m.annotate(\"TS region\", (TS_region[0], TS_region[1]-1), xycoords='data', c=\"0.5\", fontsize=8)\n",
    "\n",
    "# colorbar\n",
    "axes_c = plt.subplot(gs[2,0])\n",
    "cbar = plt.colorbar(p1, cax=axes_c, orientation='horizontal')\n",
    "clabel = f\"SLSTR night-time SST anomaly for {day} {formatted_month} {nrt_year}\"\n",
    "cbar.set_label(clabel + ' [$^{o}C$]')\n",
    "plt.savefig(\"SLSTR_anomaly_Med.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see a similiar view to what we observed in the OSTIA anomaly but at higher spatial resolution and, in practice, with more quickly available data. There is much more mesoscale variability evident in this picture, however we should be careful about how we interpret some of the eddy variability. During the last step, we interpolated the coarse (0.05 degree) OSTIA grid onto the 1 km SLSTR grid. With such a long climatology it is likely that the OSTIA field is very smooth and that the \"eddies\" we see are in fact expresison of actual dynamics. However, the OSTIA grid is too coarse to capture these features, and with short climatologies we should be wary of introducing artefacts. In general, it is better practice to always interpolate to the lower resolution grid.\n",
    "\n",
    "As before, although we can draw information from this plot, we need to bear a few caveats in mind;\n",
    "1. The OSTIA climatology we are using is reprocessed data, which is high quality, but not a climate data record. As such, it is hard to draw any climate related conclusions from this.\n",
    "2. The near-real time operational SLSTR product we are using is not the same quality as reprocessed data\n",
    "3. We are comparing *SSTskin* with *SSTfnd* under very specific circumstances (night-time), assuming no diurnal warming effect\n",
    "4. We are ignoring the skin effect\n",
    "5. We are comparing data on different grids\n",
    "\n",
    "That is a lot of caveats! However, this is the only way that we can potentially see the effects of heatwaves on small scale dynamic system in near real-time. For event scale monitoring or anomalies, there is always a trade-off to be made between data accurracy and data availability. We should take care to be clear about this in our analyses. Here the anomaly is very large (+4C!), so we can be confident that the measurement is largely realiable.\n",
    "\n",
    "*Note: you may also wish to know that OSTIA ingests SLSTR level-2P SST data and uses SLSTR as the reference sensor, so the similarities in the pattern are not so surprising!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section8'></a>8. Plotting time series\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have discussed, relatively extensively, the differences between operational and reprocessed data, but in practice what effects can these have on our anomalies? Lets take a last look at our data from a time series perspective. As before, we will stream data directly from the CMEMS Data Store, but this time write it to file as we will get every daily time-step. The cell below will manage this for us, getting all available \"full year\" data in our time seres ROI between our start and end dates for both the reprocessed and operational OSTIA collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series\n",
    "TS_MY_data = copernicusmarine.open_dataset(\n",
    "           dataset_id = dataset_my,\n",
    "           variables=['analysed_sst'],\n",
    "           minimum_longitude=TS_region[0],\n",
    "           maximum_longitude=TS_region[2],\n",
    "           minimum_latitude=TS_region[1],\n",
    "           maximum_latitude=TS_region[3],\n",
    "           start_datetime=\"{start_year}-01-01T00:00:00.000Z\".format(start_year = start_year),\n",
    "           end_datetime=\"{end_year}-12-31T00:00:00.000Z\".format(end_year = end_year),\n",
    "           ).mean(dim=[\"longitude\", \"latitude\"])\n",
    "\n",
    "TS_NRT_data = copernicusmarine.open_dataset(\n",
    "           dataset_id = dataset_nrt,\n",
    "           variables=['analysed_sst'],\n",
    "           minimum_longitude=TS_region[0],\n",
    "           maximum_longitude=TS_region[2],\n",
    "           minimum_latitude=TS_region[1],\n",
    "           maximum_latitude=TS_region[3],\n",
    "           start_datetime=\"{start_year}-01-01T00:00:00.000Z\".format(start_year = start_year),\n",
    "           end_datetime=\"{end_year}-12-31T00:00:00.000Z\".format(end_year = end_year),\n",
    "           ).mean(dim=[\"longitude\", \"latitude\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have out time series data (by default, stored as TS_???? in \"./products\") we can plot it and compare some the operational and reprocessing collections. We will use the `pandas` library and `xarray` to handle the time series, and do some simple linear regression calculations below to give us some context in terms of trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup figure\n",
    "fig = plt.figure(figsize=(16, 9), dpi=300)\n",
    "plt.rc('font', size=12)\n",
    "\n",
    "plots = [] ; labels = []; xticks = []; xtick_labels= []\n",
    "\n",
    "for DS, tag, plot_colour in zip([TS_MY_data, TS_NRT_data], [\"MY\", \"NRT\"], [\"k\", \"r\"]):\n",
    "    \n",
    "    DS[\"timeordinal\"]=(['time'],  [pd.to_datetime(x).toordinal() for x in DS.time.values])\n",
    "\n",
    "    p1, = plt.plot(DS.timeordinal, DS.analysed_sst - 273.15, linewidth=1, c=plot_colour)\n",
    "    plots.append(p1)\n",
    "    labels.append(f\"OSTIA foundation temperature ({tag})\")\n",
    "\n",
    "    # calculate trend\n",
    "    annual = DS.groupby('time.year').mean('time')\n",
    "    res = stats.linregress(annual.timeordinal[1:-1], annual.analysed_sst[1:-1] - 273.15)\n",
    "    plt.scatter(annual.timeordinal[1:-1], annual.analysed_sst[1:-1] - 273.15, c=plot_colour)\n",
    "    p2, = plt.plot(annual.timeordinal[1:-1], res.intercept + res.slope*annual.timeordinal[1:-1],\n",
    "                   color=plot_colour, linestyle=\"--\", label='fitted line')\n",
    "    plots.append(p2)\n",
    "    labels.append(f\"Annual trend ({tag})\")\n",
    "    xticks.append([datetime.datetime(ii, 1, 1).toordinal() for ii in annual.year.values])\n",
    "    xtick_labels.append(annual.year)\n",
    "    print(f\"Trend - R-squared (pvalue): {res.slope*365:.2f} K/year - {res.rvalue**2:.6f} ({res.pvalue**2:.6f})\")\n",
    "\n",
    "plt.xticks(np.array([item for sublist in xticks for item in sublist]),\n",
    "           labels=np.array([item for sublist in xtick_labels for item in sublist]),\n",
    "           rotation=90, fontsize=8)\n",
    "\n",
    "plt.grid(color='0.25', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "legend = plt.legend(plots, labels, frameon=False, bbox_to_anchor=(0.5, 1.05), loc='upper center', ncol=4)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Foundation temperature [$^{o}$C]\")\n",
    "\n",
    "plt.savefig(\"OSTIA_timeseries.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "\n",
    "## <a id='section9'></a>9. Conclusions\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our final plot we can see that, in the overlapping period, while there are similarities in the seasonal cycle betwen the reprocessed (black) and operational (black) data sets, clear diffences in the annual values (dots) are evident. We can also see that while a statistically significant warming trend is visible in both time series, the operational data shows almost double to warming rate across the whole record, and the r-squared value is low.\n",
    "\n",
    "This time series highlights that our definition of a climatology is not only inconsistent between collections, but also not static in time. The definition of our climatology period is key to quantifying our anomalies, and critical to their characterisation in. In the example or marine heatwaves, constructing a moving climatology may be more relevant, especially when it refers to time periods that are more relevant to biological systems. We will discuss this more in the next notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a href=\"../../../Index.ipynb\"><< Index</a>\n",
    "<br>\n",
    "<hr>\n",
    "<a href=\"https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/applications/ocean-case-studies\">View on GitLab</a> | <a href=\"https://training.eumetsat.int/\">EUMETSAT Training</a> | <a href=mailto:ops@eumetsat.int>Contact helpdesk for support </a> | <a href=mailto:.training@eumetsat.int>Contact our training team to collaborate on and reuse this material</a></span></p>"
   ]
  }
 ],
 "metadata": {
  "author": "Ben Loveday, Hayley Evers-King",
  "description": "This Jupyter Notebook investigates warming signals in the Mediterranean Sea and North Atlantic in 2023 using sea surface temperature data from Sentinel-3 SLSTR and CMEMS OSTIA.",
  "image": "../../../../img/thumbs/Atlantic_Med_SST_anomalies_2023_thumb.png",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "services": {
   "eumetsat": {
    "binder": {
     "link": "https://mybinder.org/v2/git/https%3A%2F%2Fgitlab.eumetsat.int%2Feumetlab%2Foceans%2Focean-training%2Fapplications%2ocean-case-studies/HEAD?urlpath=%2Ftree%2FCase_studies%2FOcean_phenomena%2FBasin_scale_variability%2FAtlantic_Med_SST_anomalies_MHW_2023%2FAtlantic_Med_SST_anomalies_2023.ipynb",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    },
    "git": {
     "link": "https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/applications/ocean-case-studies/-/blob/main/Case_studies/Ocean_phenomena/Basin_scale_variability/Atlantic_Med_SST_anomalies_MHW_2023/Atlantic_Med_SST_anomalies_2023.ipynb",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    }
   },
   "wekeo": {
    "git": {
     "link": "https://github.com/wekeo/ocean-case-studies/blob/main/Case_studies/Ocean_phenomena/Basin_scale_variability/Atlantic_Med_SST_anomalies_MHW_2023/Atlantic_Med_SST_anomalies_2023.ipynb",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    },
    "url": {
     "link": "https://jupyterhub-wekeo.apps.eumetsat.dpi.wekeo.eu/hub/user-redirect/lab/tree/public/wekeo4oceans/ocean-case-studies/Case_studies/Ocean_phenomena/Basin_scale_variability/Atlantic_Med_SST_anomalies_MHW_2023/Atlantic_Med_SST_anomalies_2023.ipynb",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    }
   }
  },
  "tags": {
   "domain": [
    "Marine",
    "Climate"
   ],
   "platform": [
    "Sentinel-3",
    "CMEMS"
   ],
   "sensor": [
    "SLSTR",
    "OSTIA"
   ],
   "service": [
    "EUMETSAT",
    "CMEMS"
   ],
   "subtheme": "Climate system monitoring - Ocean",
   "tags": "Sea surface temperature"
  },
  "title": "Exploring 2023 North Atlantic and Mediterranean SST anomalies"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
